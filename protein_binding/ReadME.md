ğŸ§¬ Protein Binding Prediction Toolkit
A lightweight, modular Python framework for exploring proteinâ€“protein and proteinâ€“peptide interactions.

This project provides two complementary pipelines:

3D-based interface scoring (using PDB structures)

NLP-based sequence embeddings (using ProtBERT)

Both pipelines share the same philosophy:
simple, interpretable, modular, and easy to extend.

ğŸ“ Project Structure
Code
protein_binding/
â”‚
â”œâ”€â”€ io.py                 # Load PDB structures
â”œâ”€â”€ features.py           # Extract interface residues
â”œâ”€â”€ models.py             # Simple 3D scoring model
â”œâ”€â”€ sampling.py           # Pose generation (placeholder)
â”œâ”€â”€ pipeline.py           # 3D end-to-end pipeline
â”‚
â”œâ”€â”€ nlp_embeddings.py     # ProtBERT embeddings for sequences
â”œâ”€â”€ nlp_models.py         # Simple NLP-based interaction model
â”œâ”€â”€ nlp_pipeline.py       # Sequence-only prediction pipeline
â”‚
â”œâ”€â”€ run.py                # Run 3D pipeline
â””â”€â”€ run_nlp.py            # Run NLP pipeline
ğŸš€ Quickstart
Install dependencies
bash
pip install torch transformers biopython scikit-learn
ğŸ§© 1. 3D Pipeline (PDB-based)
This pipeline:

Loads a protein complex from a PDB file

Identifies interface residues

Scores the interface using a simple heuristic

Ranks poses (if multiple are generated)

Run it:

bash
python run.py
You can modify run.py to point to your own PDB file:

python
pdb_path = "examples/mdm2_peptide_complex.pdb"
ğŸ§¬ 2. NLP Pipeline (Sequence-based)
This pipeline uses ProtBERT to embed protein sequences as vectors and computes an interaction probability using cosine similarity.

Run it:

bash
python run_nlp.py
Example inside run_nlp.py:

python
seq_a = "MSEQNNTEMTFQIQRIYTKDISFEAPNAPHVFQKDW"
seq_b = "GSDVVVQTPVQENYQKSVR"
Output:

Code
NLP-based proteinâ€“protein interaction prediction
------------------------------------------------
Interaction probability: 0.742
ğŸ§  Why Two Pipelines?
3D pipeline â†’ useful when you have structures (PDBs, docking outputs, AlphaFold models)

NLP pipeline â†’ useful when you only have sequences or want fast screening

You can combine both later into a hybrid model.

ğŸ› ï¸ Extending the Toolkit
This architecture is intentionally modular:

Replace simple_interface_score() with a learned model

Add real docking to sampling.py

Train a classifier in nlp_models.py

Add batch jobs for Lyceum Cloud

Integrate Rosetta/FlexPepDock outputs

Everything is plug-and-play.

ğŸ“Œ Notes
ProtBERT loads once and stays cached for fast inference

GPU acceleration is automatic if available

No external docking tools are required to get started
